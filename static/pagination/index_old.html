<!DOCTYPE html>
<html>
<head>

  <meta name="description" content="Simplest possible examples of HTML, CSS and JavaScript." />
  <meta name="author" content="//samdutton.com">
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta itemprop="name" content="simpl.info: simplest possible examples of HTML, CSS and JavaScript">
  <meta itemprop="image" content="/images/icons/icon192.png">
  <meta name="mobile-web-app-capable" content="yes">
  <meta id="theme-color" name="theme-color" content="#fff">
  <meta charset="utf-8">

  <base target="_blank">

  <title>Pagination without JavaScript</title>

  <link rel="stylesheet" href="css/main.css" />

</head>

<body>

  <header>
    <h1>High performance video for the mobile web</h1>
  </header>

  <div class="container">

    <section>

    <h2>Introduction</h2>

    <p>It's simple to add video to your website, but how can you deliver great performance even when connectivity is flakey and bandwidth is limited?</p>

    <p>In this codelab you'll find out how to get the best possible experience on any device.</p>

    </section>

    <section>

    <h2>What are you going to build?</h2>

    <p>You will build a player that enables you to deliver video using Dynamic Adaptive Streaming over HTTP (DASH).</p>

    <p><img src="insert_image_url_here"></p>

    <p>© Copyright 2008 <a href="http://blender.org">Blender Foundation</a> | <a href="https://peach.blender.org/">bigbuckbunny.org</a></p>

    </section>

    <section>

    <h2>Overview</h2>

    <p class="duration">Duration: 0:30</p>

    <p>Learn how to use adaptive streaming to deliver a great video experience across devices and platforms, even on flaky networks or offline.</p>

    <h3>What you'll learn</h3>

    <ul>
      <li>Techniques to make the most of the video element.</li>
      <li>How to build a simple adaptive streaming video player.</li>
      <li>How to add captions, subtitles and synchronised metadata.</li>
      <li>An introduction to Dynamic Adaptive Streaming over HTTP (DASH).</li>
      <li>Media delivery testing, across devices and different bandwidths.</li>
    </ul>

    <h3>What you'll need</h3>

    <ul>
      <li>Chrome 47 or above</li>
      <li><a href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb">Web Server for Chrome</a>, or use your own web server of choice.</li>
      <li>The sample code</li>
      <li>A text editor</li>
      <li>Basic knowledge of HTML, CSS and JavaScript</li>
    </ul>

    </section>

    <section>

    <h2>Get started</h2>

    <p class="duration">Duration: 2:00</p>

    <h3>Download the code</h3>

    <p>If you're familiar with git, you can download the code for this codelab from GitHub by cloning it:</p>

<blockquote class="code">
git clone https://github.com/googlecodelabs/adaptive-web-media
</blockquote>

    <p>Alternatively, click the following button to download a .zip file of the code:</p>

    <p><a href="https://github.com/googlecodelabs/adaptive-web-media/archive/master.zip">Download source code</a></p>

    <p>Open the downloaded zip file. This will unpack a project folder (<strong>adaptive-web-media</strong>) that contains one folder for each step of this codelab, along with all of the resources you will need.</p>

    <p>You'll be doing all your coding work in the directory named <strong>work</strong>.</p>

    <p>The <strong>step-nn</strong> folders contain a finished version for each step of this codelab. They are there for reference.</p>

    <h3>Install and verify web server</h3>

    <p>While you're free to use your own web server, this codelab is designed to work well with the Chrome Web Server. If you don't have that app installed yet, you can install it from the Chrome Web Store:</p>

    <p><a href="https://chrome.google.com/webstore/detail/web-server-for-chrome/ofhbbkphhbklhfoeikjpcbhemlocgigb?hl=en">Install Web Server for Chrome</a></p>

    <p><img src="insert_image_url_here"></p>

    <p>After installing the <strong>Web Server for Chrome</strong> app, click on the Chrome Apps shortcut from the bookmarks bar, a New Tab page, or from the App Launcher:</p>

    <p><img src="insert_image_url_here"></p>

    <p>Click on the Web Server icon:</p>

    <p><img src="insert_image_url_here"></p>

    <p>Next, you'll see this dialog, which allows you to configure your local web server:</p>

    <p><img src="insert_image_url_here"></p>

    <p>Click the <strong>CHOOSE FOLDER</strong> button, and select the <strong>work</strong> folder you just created. This will enable you to view your work in progress in Chrome via the URL highlighted in the Web Server dialog in the <strong>Web Server URL(s)</strong> section.</p>

    <p>Under <strong>Options</strong>, check the box next to <strong>Automatically show index.html</strong> as shown below:</p>

    <p><img src="insert_image_url_here"></p>

    <p>Then stop and restart the server by sliding the toggle labeled <strong>Web Server: STARTED</strong> to the left and then back to the right.</p>

    <p><img src="insert_image_url_here"></p>

    <p>Now visit your work site in your web browser by clicking on the highlighted Web Server URL. You should see a page that looks like this, which corresponds to <strong>work/index.html</strong>:</p>

    <p><img src="insert_image_url_here"></p>

    <p>Obviously, this app is not yet doing anything interesting — so far, it's just a minimal skeleton we're using to make sure your web server is working properly. We'll add functionality and layout features in subsequent steps.</p>

    <aside class="note">
     <p>From this point forward, all testing and verification should be performed using this web server setup. You'll usually be able to get away with simply refreshing your test browser tab.</p>
   </aside>

    </section>

    <section>

   <h2>Make the most of the video element</h2>

   <p class="duration">Duration: 5:00</p>

   <p>A completed version of this section is in the <strong>step-02</strong> folder.</p>

   <aside class="note">
     <p>In this codelab, we'll be using open source video from <a href="https://www.blender.org/">The Blender Foundation</a>.</p>
   </aside>

   <p>The <code>video</code> element is a thing of simple beauty. Download, decode and play back video with a few lines of code.</p>

   <p>Let's get started!</p>

   <p>Add a <code>video</code> element to <strong>index.html</strong> in your work folder:</p>

<blockquote class="code">
&lt;video autoplay controls src=&quot;video/bunny.webm&quot;&gt;
  &lt;p&gt;Sorry! Your browser doesn't support the video element.&lt;/p&gt;
&lt;/video&gt;
</blockquote>

  <p>Notice that the <code>video</code> element always has a closing <code>&lt;/video&gt;</code> tag: it's not 'self-closing'. Any elements inside it (such as the paragraph in this example) will be displayed if the browser doesn't support <code>video</code>.</p>

  <p>Try it out in the browser: you should see a big white rabbit.</p>

  <h3>Time fragments</h3>

  <p>You can specify a start and end time by adding a fragment to the URL. This enables multiple views on the same video.</p>

  <p>Try it out:</p>

<blockquote class="code">
&lt;video autoplay controls src=&quot;video/bunny.webm#t=25,26&quot;&gt;
  &lt;p&gt;Sorry! Your browser doesn't support the video element.&lt;/p&gt;
&lt;/video&gt;
</blockquote>

  <h3>Video formats</h3>

  <p>What if you want to serve video to Safari users? Safari supports MP4 video but not WebM.</p>

  <aside class="note">
    <p><strong>What's WebM?</strong></p>
    <p>MP4 and WebM are container formats. You can think of these a bit like .zip files, containing both audio and video components.</p>
    <p>Most commonly, MP4 stores audio using AAC compression and video using H.264.</p>
    <p>WebM uses VP8 and Vorbis or, more recently VP9 and Opus.</p>
  </aside>

  <h3>The source element</h3>

  <p>Use the <code>source</code> element to enable browsers to choose from multiple formats. MP4 and WebM cover all modern browsers, including all mobile browsers. Specify video sources in order of preference:</p>

<blockquote class="code">
&lt;video autoplay controls&gt;
  &lt;source src=&quot;video/bunny.webm&quot; /&gt;
  &lt;source src=&quot;video/bunny.mp4&quot; /&gt;
  &lt;p&gt;Sorry! Your browser doesn't support the video element.&lt;/p&gt;
&lt;/video&gt;
</blockquote>

  <p>Adding a <code>type</code> attribute to a <code>source</code> element enables the browser to select a video source without having to download part of the video to check:</p>

<blockquote class="code">
&lt;video autoplay controls&gt;
  &lt;source src=&quot;video/bunny.webm&quot; type=&quot;video/webm&quot; /&gt;
  &lt;source src=&quot;video/bunny.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;p&gt;Sorry! Your browser doesn't support the video element.&lt;/p&gt;
&lt;/video&gt;
</blockquote>

  <aside class="note">
    <p><strong>Try it out!</strong></p>
    <p>The demo at <a href="https://simpl.info/video/notype/index.html">simpl.info/video/notype</a> has <code>source</code> elements without <code>type</code> attributes. Open the page in Safari from your own computer or phone and look at network activity from Web Inspector.</p>
    <p>You'll see that Safari has to download a little bit of metadata for the WebM file to 'sniff' the format. That requires one more resource request, and additional processing, which is not good anywhere, particularly on mobile.</p>
  </aside>

  <aside class="note">
    <p><strong>Top Tip!</strong></p>
    <p>Make sure your server reports <a href="https://youtu.be/j5fYOYrsocs?t=3m56s">the correct video MIME type</a>.</p>
  </aside>

  <h3>Format support</h3>

  <p>Want to know what formats are supported by your browser?</p>

  <p>Try the video <code>canPlayType()</code> method.</p>

  <p>Add the following code to the <strong>main.js</strong> file in the <strong>js</strong>directory in your <strong>work</strong>directory:</p>

<blockquote class="code">
var videoElement = document.querySelector('video');
console.log('fubar', videoElement.canPlayType('fubar'));
console.log('webm', videoElement.canPlayType('video/webm'));
console.log('webm/vp8', videoElement.canPlayType('video/webm; codecs="vp8"'));
</blockquote>

  <p>Take a look at the output from the DevTools console.</p>

  <p>There are many factors that affect whether or not a browser can play a particular format, so the browser cannot give a definite yes or no answer to <code>canPlayType()</code>. Hence the <code>maybe</code> and <code>probably v</code>alues! An empty string means the container and codec combination is definitely not supported.</p>

  <h3>Video src</h3>

  <p>Want to know which source was actually chosen? Add this to your JavaScript:</p>

<blockquote class="code">
console.log(videoElement.currentSrc);
</blockquote>

  <h3>Video size and display size</h3>

  <p>While you're there, you can get the actual height and width of the video. That might be different from the dimensions of the video element — in the same way that images can be displayed bigger or smaller than their actual size. For this, you need to wait until the video metadata is loaded:</p>

<blockquote class="code">
videoElement.onloadedmetadata = function() {
  console.log(this.videoWidth);
  console.log(this.videoHeight);
};
</blockquote>

<p>Thinking about display size and CSS, a simple technique for video is to specify a <code>width</code> and a <code>max-width</code>. That way you get a preferred size, but the video never overflows its container. Don't specify a height: the browser will work that out automatically. That way you'll keep the right aspect ratio. Much easier and less error prone than trying to calculate it manually!</p>

<p>Add the following to <strong>main.css</strong> in the <strong>work/css</strong> folder:</p>

<blockquote class="code">
  video {
    width: 640px;
    max-width: 100%;
}
</blockquote>

<h3>The poster attribute</h3>

<p>Last but not least, let's add a poster image: an image displayed before playback, as soon as a video element is rendered.</p>

<p>There's already a poster image in the <strong>work/images</strong> folder: <strong>poster.jpg</strong>. Add a <code>poster</code> attribute to the opening tag of the <code>video</code> element:</p>

<blockquote class="code">
&lt;video autoplay controls poster="images/poster.jpg"&gt;
</blockquote>

<p>Including a poster attribute gives viewers a meaningful idea of content without needing to download video or start playback. The only downside is that using a poster image incurs an additional file request, which consumes a little bit of bandwidth and requires rendering.</p>

<aside class="note">
  <p><strong>Choose the right resolution</strong></p>
  <p> Serve video at an appropriate resolution for the target device — not too big, not too small. Don't just tweak the video element size! There's no point in serving 1080x1920 files to phones with a small viewport when 360x640px looks just as good.</p>
  <p>You can use media queries to choose a different video depending on the viewport dimensions. Try this out at <a href="https://simpl.info/video/mq">simpl.info/video/mq</a>: with a bigger viewport, you get the bigger video, and with a smaller viewport you get the smaller video.</p>
</aside>

<h3>Learn more</h3>

<ul>
  <li><a href="https://www.youtube.com/watch?v=j5fYOYrsocs">Video on mobile</a></li>
  <li><a href="https://peach.blender.org/">Big Buck Bunny</a>: more about the video used in this codelab</li>
</ul>

    </section>

    <section>

<h2>Add subtitles, captions &amp; descriptions</h2>

<p class="duration">Duration: 2:00</p>

<p>A completed version of this section is in the <strong>step-03</strong> folder.</p>

<p>It's easy to make audio and video more accessible to a wider audience by adding subtitles, titles or descriptions.</p>

<p>This can be done by adding a <code>track</code> element as a child of a <code>video</code> or <code>audio</code> element. The <code>track</code> element's <code>src</code> attribute points to a file that gives information about text (such as subtitles) to be displayed by the browser during playback. A track file consists of timed ‘cues' in a plain text file.</p>

<p>Create a directory named <strong>track</strong> in your <strong>work</strong>folder and add a new file named <strong>track.vtt</strong>. Add the following text to that file:</p>

<blockquote class="code">
  WEBVTT FILE

  00:00:00.000 --&gt; 00:00:02.000
  Opening titles

  00:00:03.500 --&gt; 00:00:05.000
  A rabbit hole at the base of a tree

  00:00:09.000 --&gt; 00:00:11.000
  An enormous white rabbit in a field

  00:00:13.000 --&gt; 00:00:14.500
  Three rodents, one throws an acorn at the rabbit

  00:00:15.500 --&gt; 00:00:16.750
  The rabbit looks shocked
</blockquote>

<p>This format is called WebVTT.</p>

<p>Add the following <code>track</code> element  as a child of your <code>video</code> element:</p>

<blockquote class="code">
  &lt;track label="Descriptions" src="tracks/track.vtt" /&gt;
</blockquote>

<p>Your <code>video</code> element code should now look like this:</p>

<blockquote class="code">
&lt;video autoplay controls  poster=&quot;images/poster.jpg&quot;&gt;
  &lt;source src=&quot;video/bunny.webm&quot; type=&quot;video/webm&quot; /&gt;
  &lt;source src=&quot;video/bunny.mp4&quot; type=&quot;video/mp4&quot; /&gt;
  &lt;track label=&quot;Descriptions&quot; src=&quot;tracks/track.vtt&quot; /&gt;
  &lt;p&gt;Sorry! Your browser doesn't support the video element.&lt;/p&gt;
&lt;/video&gt;
</blockquote>

<p>Open your page in the browser, click on the captions button at the right of the video controls and select Descriptions:</p>

<p><img src="insert_image_url_here"></p>

<p>The video should now display the descriptions you added — feel free to embellish them.</p>

<p><img src="insert_image_url_here"></p>

<p>The track element is supported by <a href="http://caniuse.com/#feat=webvtt">all modern browsers</a> on desktop and mobile — so make the most of it!</p>

<p>You can also get and set text tracks in JavaScript, and listen out for cue changes.  Take a look at this example from <a href="https://simpl.info/track/">simpl.info/track</a>:</p>

<blockquote class="code">
'use strict';
var videoElement = document.querySelector('video');
var textTrack = videoElement.textTracks[0]; // there's only one!
var data = document.getElementById('data');
textTrack.oncuechange = function() {
  // 'this' is a textTrack
  var cue = this.activeCues[0]; // assuming there is only one active cue
  if (cue) {
    data.innerHTML = cue.startTime + '-' + cue.endTime + ': ' + cue.text +
    '<br />' + data.innerHTML;
    //  var obj = JSON.parse(cue.text); // cues can be data too :)
  }
};
</blockquote>

<aside class="note">
  <p><strong>Using tracks for synchronised metadata</strong></p>
  <p>The track element can be used to synchronise any metadata with media playback — not just subtitles.</p>
  <p>You can add data (such as json) to cues, then parse the value of the cues when the track  <code>cuechange</code> event is fired.</p>
  <p><a href="http://samdutton.com/map">This demo</a> shows how the track element can be used to synchronise video playback with the position of a map marker, and make synchronised changes to DOM elements. The position of the map marker changes corresponding to the current time of the video. Time of day is overlaid on the video.</p>
</aside>

<aside class="warning">
  <p><strong>Tracks and tracks</strong></p>
  <p>Don't confuse the track element and the <a href="http://www.html5rocks.com/en/tutorials/track/basics/#toc-cues-js">TextTrack API</a> with <a href="https://developer.mozilla.org/docs/Web/API/MediaStream">MediaStreamTrack</a>: they are related but entirely different!</p>
</aside>

<h3>Learn more</h3>

<ul>
  <li><a href="http://www.html5rocks.com/en/tutorials/track/basics/">Getting started with the track element</a></li>
  <li><a href="https://dev.opera.com/articles/an-introduction-to-webvtt-and-track/">An introduction to WebVTT and <track></a></li>
  <li><a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/track">Mozilla Developer Network: <track></a></li>
</ul>

    </section>

    <section>

<h2>Build a video stream in JavaScript</h2>

<p class="duration">Duration: 2:00</p>

<p>A completed version of this section is in the <strong>step-04</strong> folder.</p>

<p>The source element makes it possible for the browser to choose between multiple formats,</p>

<p>Modern browsers make 'partial requests' for video rather than waiting for a whole video to download.</p>

<p>To see this in action, open <a href="https://simpl.info/longvideo">simpl.info/longvideo</a>:</p>

<p><img src="insert_image_url_here"></p>

<p>Open the Network panel of the Chrome DevTools, select Media, move around between different times in the video, and you'll see lots of requests for the same video. What's going on?</p>

<p><img src="insert_image_url_here"></p>

<p>Click on one of the network responses, view the Request headers, and you'll see something like this:</p>

<p><img src="insert_image_url_here"></p>

<p>The browser has added a <code>range</code> header to the request, specifying a start point in the video in bytes. As long as the server supports range requests, it will return video data starting from that point.</p>

<p>Getting smaller segments is a better approach than waiting for monolithic video downloads, but the decisions are all made by the browser.</p>

<p>What if you wanted to choose between <i>different</i> video sources — adapting to bandwidth, for example?</p>

<p>The <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaSource">MediaSource Extensions</a> API (MSE) gives you more control by making it possible to construct video streams in JavaScript. You can request segments of video using the Fetch API or XHR, then stitch the segments together and buffer them for a video element using MSE.</p>

<p>You can see MSE in action at <a href="https://simpl.info/mse">simpl.info/mse</a>:</p>

<p><img src="insert_image_url_here"></p>

<p>In this example, video is retrieved via XHR, the video is divided up and stored locally using the File APIs, then MSE creates a buffer to feed the video element.</p>

<h3>Learn more</h3>

<ul>
  <li><a href="http://www.w3.org/TR/media-source/">W3C MSE specification</a></li>
  <li><a href="http://updates.html5rocks.com/2011/11/Stream-video-using-the-MediaSource-API">Stream video using the Media Source API</a></li>
  <li><a href="http://html5-demos.appspot.com/static/media-source.html">Demo using MSE and the File APIs</a></li>
</ul>

    </section>

    <section>

<h2>Implement adaptive streaming</h2>

<p class="duration">Duration: 2:00</p>

<p>A completed version of this section is in the <strong>step-05</strong> folder.</p>

<p>It's useful to be able to build video streams in JavaScript, but how can a video player adapt dynamically to device capabilities and current network conditions?</p>

<h3>DASH: Dynamic Adaptive Streaming over HTTPS</h3>

<p>This is where DASH comes in.</p>

<p>With DASH, you deliver video in segments over a normal HTTP connection. Each segment is made available at a variety of bitrates, resolutions and formats.The client chooses the best possible version, depending on bandwidth and device capabilities. Using HTTP enables content delivery with all the advantages of HTTP — and without the disadvantages of a traditional streaming server. No proprietary protocols or hardware are required.</p>

<p>However, rolling your own DASH solution can be complex.</p>

<p>Shaka Player is a simple-to-use DASH JavaScript library from Google built on MSE and other Web standards. Shaka also supports multilingual content for audio tracks and subtitles.</p>

<aside class="note">
  <p>Shaka Player also enables delivery of protected content, using the EME APIs to get licences and do decryption. To find out more take a look at the <a href="http://shaka-player-demo.appspot.com/docs/api/tutorial-drm-config.html">Shaka DRM documentation</a>.</p>
</aside>

<p>Let's get started.</p>

<p>Replace everything in <strong>main.js</strong> with the following:</p>

<blockquote class="code">
 'use strict';
 var manifestUri = 'https://storage.googleapis.com/shaka-demo-assets/sintel/dash.mpd';
 // Install built-in polyfills to patch browser incompatibilities.
 shaka.polyfill.installAll();
 // Check to see if the browser supports the basic APIs Shaka needs.
 // This is an asynchronous check.
 shaka.Player.support().then(function(support) {
   // This executes when the asynchronous check is complete.
   if (support.supported) {
   // Everything looks good!
   initPlayer();
} else {
  // This browser does not have the minimum set of APIs you need.
  console.error('Browser not supported!');
}
});

function initPlayer() {
  // Create a Player instance.
  var video = document.querySelector('video');
  var player = new shaka.Player(video);
  player.configure({
  preferredTextLanguage: 'en'
});
// Add player to global scope so it's visible from the browser console
window.player = player;
// Listen for error events.
player.addEventListener('error', onErrorEvent);
// Try to load a manifest.
// This is an asynchronous process.
player.load(manifestUri).then(function() {
  // This runs if the asynchronous load is successful.
  console.log('The video has now been loaded!');
}).catch(onError); // onError is executed if the asynchronous load fails.
}

function onErrorEvent(event) {
  // Extract the shaka.util.Error object from the event.
  onError(event.detail);
}

function onError(error) {
  console.error('Error code', error.code, 'object', error);
}
</blockquote>

<p>In <strong>index.html</strong> replace the video element and the script elements:</p>

<blockquote class="code">
  &lt;video controls autoplay&gt;&lt;/video&gt;

  &lt;script src=&quot;js/dist/shaka-player.compiled.js&quot;&gt;&lt;/script&gt;
  &lt;script src=&quot;js/main.js&quot;&gt;&lt;/script&gt;
</blockquote>

<p>That's it!</p>

<p>Open <strong>index.html</strong> in your browser, and you should see <a href="https://durian.blender.org/">Sintel</a>, an open source film from the <a href="https://www.blender.org/institute/">Blender Institute</a>.</p>

<h3>How it works</h3>

<p>The code in <strong>main.js</strong> uses Shaka player to implement DASH. Code for Shaka is in <strong>js/dist/shaka-player.compiled.js</strong>.</p>

<aside class="note">
  <p>The JavaScript for Shaka is compiled using <a href="https://developers.google.com/closure/compiler/">Closure</a>, which makes it efficient to use, but hard to read.</p>
  <p>If you'd like to learn more about how Shaka is architected and coded, the <a href="http://shaka-player-demo.appspot.com/docs/api/index.html">API docs</a> are a good place to start.</p>
</aside>

<p>The JavaScript in <strong>main.js</strong> does the following:</p>

<ol>
  <li>Install polyfills.</li>
  <li>Check for browser support.</li>
  <li>Create a Player object to wrap the video element.</li>
  <li>Listen for errors.</li>
  <li>Get and parse the DASH manifest.</li>
  <li>Get media segments via XHR and create a stream using MSE.</li>
</ol>

<h3>What's a manifest?</h3>

<p>A DASH manifest is an XML file that describes alternative sources for each segment of video and audio — and also any text tracks for subtitles, captions and descriptions.</p>

<p>The manifest is created programmatically when a media file is encoded and/or segmented for DASH delivery.</p>

<p>Shaka estimates bandwidth and checks device capability using <code>canPlayType()</code>. (Remember that from the previous step?) Shaka can then fetch appropriate segments of audio and video via XHR, using the information from the manifest. Once the segments are received, they can be stitched together to form a stream using MSE.</p>

<p>Subtitles, captions and descriptions are also retrieved (if available) and set for the video using the TextTrack API.</p>

<p>Take a look at the manifest used in this codelab, <a href="http://storage.googleapis.com/shaka-demo-assets/sintel/dash.mpd">dash.mpd</a>. Part of this is shown below:</p>

<blockquote class="code">
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;

&lt;!--Generated with &lt;a href=&quot;https://github.com/google/edash-packager&quot;&gt;https://github.com/google/edash-packager&lt;/a&gt; version fe6775a-release--&gt;

&lt;MPD xmlns=&quot;urn:mpeg:dash:schema:mpd:2011&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xlink=&quot;http://www.w3.org/1999/xlink&quot; xsi:schemaLocation=&quot;urn:mpeg:dash:schema:mpd:2011 DASH-MPD.xsd&quot; xmlns:cenc=&quot;urn:mpeg:cenc:2013&quot; minBufferTime=&quot;PT2S&quot; type=&quot;static&quot; profiles=&quot;urn:mpeg:dash:profile:isoff-on-demand:2011&quot; mediaPresentationDuration=&quot;PT888.0533447265625S&quot;&gt;

  &lt;Period id=&quot;0&quot;&gt;
    &lt;AdaptationSet id=&quot;0&quot; contentType=&quot;text&quot; lang=&quot;nl&quot;&gt;
      &lt;Representation id=&quot;0&quot; bandwidth=&quot;256&quot; mimeType=&quot;text/vtt&quot;&gt;
        &lt;BaseURL&gt;s-dut.webvtt&lt;/BaseURL&gt;
      &lt;/Representation&gt;
    &lt;/AdaptationSet&gt;
    &lt;AdaptationSet id=&quot;1&quot; contentType=&quot;text&quot; lang=&quot;en&quot;&gt;
      &lt;Representation id=&quot;1&quot; bandwidth=&quot;256&quot; mimeType=&quot;text/vtt&quot;&gt;
        &lt;BaseURL&gt;s-eng.webvtt&lt;/BaseURL&gt;
      &lt;/Representation&gt;
    &lt;/AdaptationSet&gt;
    ...
    &lt;AdaptationSet id=&quot;10&quot; contentType=&quot;video&quot; maxWidth=&quot;3840&quot; maxHeight=&quot;1636&quot; frameRate=&quot;1000000/42000&quot; par=&quot;40:17&quot;&gt;
      &lt;Representation id=&quot;10&quot; bandwidth=&quot;216910&quot; codecs=&quot;vp9&quot; mimeType=&quot;video/webm&quot; sar=&quot;427:426&quot; width=&quot;426&quot; height=&quot;182&quot;&gt;
        &lt;BaseURL&gt;v-0240p-0300k-vp9.webm&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;24075612-24076886&quot; timescale=&quot;1000000&quot;&gt;
          &lt;Initialization range=&quot;0-282&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
      &lt;Representation id=&quot;11&quot; bandwidth=&quot;393793&quot; codecs=&quot;vp9&quot; mimeType=&quot;video/webm&quot; sar=&quot;639:640&quot; width=&quot;640&quot; height=&quot;272&quot;&gt;
        &lt;BaseURL&gt;v-0360p-0550k-vp9.webm&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;43709632-43710931&quot; timescale=&quot;1000000&quot;&gt;
          &lt;Initialization range=&quot;0-284&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
      ...
      &lt;Representation id=&quot;14&quot; bandwidth=&quot;132318&quot; codecs=&quot;mp4a.40.2&quot; mimeType=&quot;audio/mp4&quot; audioSamplingRate=&quot;48000&quot;&gt;
        &lt;AudioChannelConfiguration schemeIdUri=&quot;urn:mpeg:dash:23003:3:audio_channel_configuration:2011&quot; value=&quot;2&quot;/&gt;
        &lt;BaseURL&gt;a-eng-0128k-aac.mp4&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;745-1844&quot; timescale=&quot;48000&quot;&gt;
          &lt;Initialization range=&quot;0-744&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
    &lt;/AdaptationSet&gt;
    &lt;AdaptationSet id=&quot;12&quot; contentType=&quot;audio&quot; lang=&quot;en&quot;&gt;
      &lt;Representation id=&quot;16&quot; bandwidth=&quot;110385&quot; codecs=&quot;vorbis&quot; mimeType=&quot;audio/webm&quot; audioSamplingRate=&quot;48000&quot;&gt;
        &lt;AudioChannelConfiguration schemeIdUri=&quot;urn:mpeg:dash:23003:3:audio_channel_configuration:2011&quot; value=&quot;2&quot;/&gt;
        &lt;BaseURL&gt;a-eng-0128k-libvorbis.webm&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;12251633-12253142&quot; timescale=&quot;1000000&quot;&gt;
          &lt;Initialization range=&quot;0-4550&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
    &lt;/AdaptationSet&gt;
    &lt;AdaptationSet id=&quot;13&quot; contentType=&quot;video&quot; maxWidth=&quot;3840&quot; maxHeight=&quot;1636&quot; frameRate=&quot;12288/512&quot; subsegmentAlignment=&quot;true&quot; par=&quot;40:17&quot;&gt;
      &lt;Representation id=&quot;17&quot; bandwidth=&quot;100729&quot; codecs=&quot;avc1.42c01e&quot; mimeType=&quot;video/mp4&quot; sar=&quot;110:109&quot; width=&quot;256&quot; height=&quot;110&quot;&gt;
        &lt;BaseURL&gt;v-0144p-0100k-libx264.mp4&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;828-1747&quot; timescale=&quot;12288&quot;&gt;
          &lt;Initialization range=&quot;0-827&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
      ...
      &lt;Representation id=&quot;28&quot; bandwidth=&quot;9270693&quot; codecs=&quot;avc1.640028&quot; mimeType=&quot;video/mp4&quot; sar=&quot;1:1&quot; width=&quot;2560&quot; height=&quot;1090&quot;&gt;
        &lt;BaseURL&gt;v-1440p-9000k-libx264.mp4&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;812-1731&quot; timescale=&quot;12288&quot;&gt;
          &lt;Initialization range=&quot;0-811&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
      &lt;Representation id=&quot;29&quot; bandwidth=&quot;17674702&quot; codecs=&quot;avc1.640028&quot; mimeType=&quot;video/mp4&quot; sar=&quot;1636:1635&quot; width=&quot;3840&quot; height=&quot;1636&quot;&gt;
        &lt;BaseURL&gt;v-2160p-17000k-libx264.mp4&lt;/BaseURL&gt;
        &lt;SegmentBase indexRange=&quot;831-1750&quot; timescale=&quot;12288&quot;&gt;
          &lt;Initialization range=&quot;0-830&quot;/&gt;
        &lt;/SegmentBase&gt;
      &lt;/Representation&gt;
    &lt;/AdaptationSet&gt;
  &lt;/Period&gt;

&lt;/MPD&gt;
</blockquote>

<p>This is not meant to be human readable! The main thing to understand is that the manifest enables the player to choose alternative formats for the same content and bitrate – in this example, WebM as well as MP4.</p>

<p>Great for media delivery to a range of devices and connectivity!</p>

<aside class="note">
  <p>Shaka implements <a href="https://shaka-player-demo.appspot.com/docs/api/shakaExtern.AbrManager.html">its own bandwidth estimator</a>, which enables it to choose different resolutions and bitrates accordingly, but Shaka can also use a plugin instead.</p>
</aside>

<h3>How do DASH players get audio and video?</h3>

<p>Take a look at the Chrome DevTools Network panel to see what's going on.</p>

<p>Note that you need to select <strong>XHR</strong> or <strong>All</strong>, not <strong>Media</strong>:</p>

<p><img src="insert_image_url_here"></p>

<p>You'll see that Shaka has retrieved a number of files:</p>

<ul>
  <li>The manifest, dash.mpd.</li>
  <li>Multiple .mp4 audio and .webm video segments.</li>
  <li>Several WebVTT subtitle files.</li>
</ul>

<p>Let's take a closer look:</p>

<p><img src="insert_image_url_here"></p>

<p>From this you can see that different resolutions and bitrates have been retrieved as Shaka adjusts to changing bandwidth. You can also check the Headers for each request:</p>

<p><img src="insert_image_url_here"></p>

<p>Note the Range header (remember that from the previous step?) and how the Request URL relates to the URL from the manifest.</p>

<h3>Subtitles, captions and descriptions</h3>

<p>It's possible to add text tracks to HTML5 video either declaratively by adding a <code>&lt;track&gt;</code> element pointing to a WebVTT file, or via JavaScript using <a href="http://www.html5rocks.com/en/tutorials/track/basics/#toc-cues-js">TextTrack API</a> — which is what Shaka does.</p>

<p>You can turn on subtitles by clicking on the CC button near the bottom right of the player:</p>

<p><img src="insert_image_url_here"></p>

<p>(This shows a still from the open source film Sintel, © copyright Blender Foundation | <a href="http://www.sintel.org">sintel.org</a>.)</p>

<p>From the DevTools console, you can set the subtitle language:</p>

<blockquote class="code">
  player.configure({preferredTextLanguage: 'fr'});
</blockquote>

<p>From the DevTools, also take a look at the WebVTT files and the text track options in dash.mpd.</p>

<aside class="note">
  <p>If a video has audio tracks for different languages, you can set the language from the player.</p>
  <p>For example:</p>
  <p><code>player.configure({preferredAudioLanguage: 'fr'});</code></p>
</aside>

<p>The <code>player.getConfiguration()</code> and <code>player.getStats()</code> methods provide more information about video playback and the player environment:</p>

<p><img src="insert_image_url_here"></p>

<h3>Learn more</h3>

<ul>
  <li><a href="https://github.com/google/shaka-player">Shaka Player repo, tutorials and documentation</a></li>
  <li><a href="https://www.youtube.com/watch?v=Fm3Bagcf9Oo">High performance video for the web</a>: video about DASH and Shaka Player</li>
  <li><a href="https://msdn.microsoft.com/en-us/library/dn551368(v=vs.85).aspx">Building a simple MPEG-DASH streaming player</a>: detailed article explaining how to build your own DASH player</li>
  <li><a href="https://durian.blender.org/">Sintel</a>: more about the movie used for this codelab</li>
</ul>

    </section>

    <section>

<h2>Congratulations!</h2>

<p class="duration">Duration: 2:00</p>

<p>You built a multi-platform, adaptive video player that can display subtitles.</p>

<p><img src="insert_image_url_here"></p>

<h3>What you've covered</h3>

<ul>
  <li>Techniques to make the most of the video element.</li>
  <li>How to build a simple adaptive streaming video player.</li>
  <li>How to add captions, subtitles and synchronised metadata.</li>
  <li>An introduction to Dynamic Adaptive Streaming over HTTP (DASH).</li>
  <li>Media delivery testing, across devices and different bandwidths.</li>
</ul>

<h3>Next Steps</h3>

<ul>
  <li>Try out the <a href="http://shaka-player-demo.appspot.com/docs/api/tutorial-basic-usage.html">Shaka Player demo</a>: a fully featured app including multiple DRM and encoding options</li>
  <li>Learn more about Shaka's <a href="https://github.com/google/shaka-player">codebase and the API architecture</a> </li>
  <li>Get to grips with APIs for DRM: <a href="http://www.html5rocks.com/en/tutorials/eme/basics/">EME WTF?</a></li>
</ul>

<h3>Learn More</h3>

<ul>
  <li><a href="https://xiph.org/video/vid1.shtml">A Digital Media Primer for Geeks</a>: a great quirky introduction to the science behind digital audio and video</li>
</ul>

</div>

</footer>

</body>

</html>
